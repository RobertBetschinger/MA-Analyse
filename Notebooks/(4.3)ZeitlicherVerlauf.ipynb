{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4a65ed78",
   "metadata": {},
   "source": [
    "## Load and preprocess data, then calculate the number of unique algorithmic and non-algorithmic sellers.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a24fcf29",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of duplicate rows: 0\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "##Read in the Sellers who are algorithmic\n",
    "df_algorithmic_seller_names = pd.read_csv('../Grunddatein/Zwischendatein/PA-Adopters.csv')\n",
    "# rename column\n",
    "df_algorithmic_seller_names = df_algorithmic_seller_names.rename(columns={'AlgorithmicSellerNames': 'sellerName'})  \n",
    "# Check for duplicates in the entire DataFrame\n",
    "duplicate_rows = df_algorithmic_seller_names.duplicated()\n",
    "print(f\"Number of duplicate rows: {duplicate_rows.sum()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "04d87ad0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "KeyboardInterrupt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "df = pd.read_csv('../Grunddatein/Zwischendatein/CleanedDataCompleteNoNulls.csv')\n",
    "df[\"time\"] = pd.to_datetime(df[\"time\"], format=\"%Y-%m-%d %H:%M:%S\")\n",
    "\n",
    "##Transform CrawlTime Column to DateTime Format\n",
    "df['crawlTime'] = pd.to_datetime(df['crawlTime'])\n",
    "\n",
    "## Exclude all Rows where condition isnt New and which where a reactive Crawl\n",
    "df = df[df['condition'].isin(['Neu', 'New'])]\n",
    "\n",
    "##Get the Number of Distinct Values\n",
    "distinct_values_verkäufer = df['sellerName'].unique()\n",
    "print(f\"Es gibt insgesamt {len(distinct_values_verkäufer)} verschiedene Verkäufer\")\n",
    "\n",
    "# Create a new column to indicate if the seller is algorithmic or not\n",
    "df['is_algorithmic'] = df['sellerName'].isin(df_algorithmic_seller_names['sellerName'])\n",
    "\n",
    "# Calculate the number of algorithmic and non-algorithmic sellers\n",
    "num_algo_sellers = df[df['is_algorithmic']]['sellerName'].nunique()\n",
    "num_non_algo_sellers = df[~df['is_algorithmic']]['sellerName'].nunique()\n",
    "\n",
    "print(f\"Es gibt insgesamt {num_non_algo_sellers} Non-Algo Verkäufer\")\n",
    "print(f\"Es gibt insgesamt {num_algo_sellers} Algo Verkäufer\")\n",
    "print(f\"Sie Summieren sich richtig auf\",num_algo_sellers + num_non_algo_sellers == len(distinct_values_verkäufer))\n",
    "\n",
    "# Create two separate DataFrames for non-algorithmic and algorithmic seller names\n",
    "non_algo_seller_names = df.loc[df['is_algorithmic'] == False, 'sellerName'].unique()\n",
    "algo_seller_names = df.loc[df['is_algorithmic'] == True, 'sellerName'].unique()\n",
    "\n",
    "df_non_algo_names = pd.DataFrame(non_algo_seller_names, columns=['sellerName'])\n",
    "df_algo_names = pd.DataFrame(algo_seller_names, columns=['sellerName'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7436777e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d67ce93",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter dataframe for each seller\n",
    "df_at_memory = df[df['sellerName'] == 'Schuh-Helden']\n",
    "df_skyline_media = df[df['sellerName'] == 'Schuh-Lounge24']\n",
    "\n",
    "# Get unique ASINs for each seller\n",
    "asins_at_memory = set(df_at_memory['asin'].unique())\n",
    "asins_skyline_media = set(df_skyline_media['asin'].unique())\n",
    "\n",
    "# Find ASINs that appear in both sets (i.e., the intersection of the sets)\n",
    "common_asins = asins_at_memory & asins_skyline_media\n",
    "\n",
    "# Print the result\n",
    "print(common_asins)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "844fb6ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define a function to extract hour from datetime column\n",
    "def get_hour(datetime_val):\n",
    "    return datetime_val.hour\n",
    "\n",
    "# apply the get_hour function to the 'time' column using apply method\n",
    "df['hourTime'] = df['time'].apply(get_hour)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b1be8ee",
   "metadata": {},
   "source": [
    "## Alle Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60a4987e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "# Extract unique ASINs\n",
    "unique_asins = df['asin'].unique()\n",
    "\n",
    "# Loop over unique ASINs\n",
    "for asin in unique_asins:\n",
    "    # Filter DataFrame for the selected ASIN and select necessary columns\n",
    "    asin_df = df[df['asin'] == asin][['time', 'price', 'sellerId', 'is_algorithmic']].copy()\n",
    "\n",
    "    # Convert 'time' to datetime object\n",
    "    asin_df['time'] = pd.to_datetime(asin_df['time'])\n",
    "\n",
    "    # Group by 'time', 'sellerId', and 'is_algorithmic', calculate mean of 'price'\n",
    "    grouped_df = asin_df.groupby(['time', 'sellerId', 'is_algorithmic']).mean().reset_index()\n",
    "\n",
    "    # Add algorithmic info to sellerId\n",
    "    grouped_df['sellerId'] = grouped_df.apply(lambda row: f\"{row['sellerId']} (Algorithmic)\" if row['is_algorithmic'] else f\"{row['sellerId']}\", axis=1)\n",
    "\n",
    "    # Pivot the DataFrame\n",
    "    pivot_df = grouped_df.pivot(index='time', columns='sellerId', values='price')\n",
    "\n",
    "    # Plot the data\n",
    "    fig, ax = plt.subplots(figsize=(15, 7))\n",
    "    pivot_df.plot(kind='line', ax=ax)\n",
    "    plt.xlabel('Time')\n",
    "    plt.ylabel('Price')\n",
    "    plt.title(f'Price History Across Sellers for Asin: {asin}')\n",
    "    plt.tight_layout()\n",
    "\n",
    "    # Move the legend outside the plot on the right\n",
    "    ax.legend(loc='center left', bbox_to_anchor=(1, 0.5))\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "    print(\"This is the ASIN\", asin)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45151f8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Interessante ASINS\n",
    "normalSeller = ['B000MJR8UO']\n",
    "now = ['B077T3QZ1H','B0062VH4NM']\n",
    "night = ['B001R4BR1O','B00605N1G4']\n",
    "auch_interesant = ['B001IL99I4','B00DG89W0W']\n",
    "asins_perfect_matching = ['B0062VH4NM','B0797CV4TX','B07RY6RDV7','B077T3QZ1H','B07ZHBJRWF','B07WQPDC72',]\n",
    "asins_intresting = ['B099NPYRVF','B00J7GVPY8','B0196Q9PVS','B000GISU1M','B09R1QSHN9','B07MTG5V14',]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6023be8",
   "metadata": {},
   "source": [
    "## Interesante ASINS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69b3b0f3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "asins_perfect_matching = ['B0062VH4NM','B0797CV4TX','B07RY6RDV7','B077T3QZ1H','B07ZHBJRWF','B07WQPDC72',]\n",
    "asins_intresting = ['B00J7GVPY8','B000GISU1M','B09R1QSHN9']\n",
    "\n",
    "# Extract unique ASINs\n",
    "unique_asins = df['asin'].unique()\n",
    "\n",
    "exclude_sellers = ['amazon','AMTZEDNZE6EVF','A1WUUK7EBFTPLY', 'A2QA60OP8EX7O6',   'ABJ00Z4TWCDSX','ABJ00Z4TWCDSX','ACMWIN42TGI9W']\n",
    "\n",
    "\n",
    "# Loop over unique ASINs\n",
    "for asin in normalSeller:\n",
    "    # Filter DataFrame for the selected ASIN and select necessary columns\n",
    "    asin_df = df[(df['asin'] == asin) & (~df['sellerId'].isin(exclude_sellers))][['time', 'price', 'sellerId', 'is_algorithmic']].copy()\n",
    "\n",
    "    # Convert 'time' to datetime object\n",
    "    asin_df['time'] = pd.to_datetime(asin_df['time'])\n",
    "\n",
    "    # Create a mapping from unique seller ids to anonymized names\n",
    "    unique_sellers = asin_df['sellerId'].unique()\n",
    "    seller_mapping = {seller: f'seller-{i+1}' if seller != 'amazon' else 'amazon' for i, seller in enumerate(unique_sellers)}\n",
    "\n",
    "    # Replace seller ids with anonymized names\n",
    "    asin_df['sellerId'] = asin_df['sellerId'].map(seller_mapping)\n",
    "\n",
    "    # Group by 'time', 'sellerId', and 'is_algorithmic', calculate mean of 'price'\n",
    "    grouped_df = asin_df.groupby(['time', 'sellerId', 'is_algorithmic']).mean().reset_index()\n",
    "\n",
    "    # Add algorithmic info to sellerId\n",
    "    grouped_df['sellerId'] = grouped_df.apply(lambda row: f\"{row['sellerId']} (Algorithmic)\" if row['is_algorithmic'] else f\"{row['sellerId']}\", axis=1)\n",
    "\n",
    "    # Pivot the DataFrame\n",
    "    pivot_df = grouped_df.pivot(index='time', columns='sellerId', values='price')\n",
    "\n",
    "    # Print anonymized seller names\n",
    "    print(\"Seller IDs for ASIN \", asin, \": \", pivot_df.columns.tolist())\n",
    "\n",
    "    # Plot the data\n",
    "    fig, ax = plt.subplots(figsize=(15, 7))\n",
    "    pivot_df.plot(kind='line', ax=ax)\n",
    "    plt.xlabel('Time')\n",
    "    plt.ylabel('Price')\n",
    "    plt.title(f'Price History Across Sellers for Asin: {asin}')\n",
    "    plt.tight_layout()\n",
    "\n",
    "    # Move the legend outside the plot on the right\n",
    "    ax.legend(loc='center left', bbox_to_anchor=(1, 0.5))\n",
    "\n",
    "    # Save the plot to a PNG file, including the legend\n",
    "    plt.savefig(f'{asin}_plot.png', bbox_inches='tight')\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "    print(\"This is the ASIN\", asin)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d196f1e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a23925a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter DataFrame for the specified ASIN and sellerId\n",
    "asin_seller_df = df[(df['asin'] == \"B00605N1G4\") & (df['sellerId'] == \"ABGAQ3TO9PA1P\")]\n",
    "\n",
    "# Calculate the mean price over the whole day\n",
    "mean_price_all_day = asin_seller_df['price'].mean()\n",
    "print(f\"Mean price over the whole day: {mean_price_all_day}\")\n",
    "\n",
    "# Calculate the mean price during the early morning (03:00 - 05:00)\n",
    "mean_price_early_morning = asin_seller_df[asin_seller_df['hourTime'].apply(lambda x: 3 <= x < 5)]['price'].mean()\n",
    "print(f\"Mean price during the early morning (03:00 - 05:00): {mean_price_early_morning}\")\n",
    "\n",
    "# Calculate the mean price during the day excluding early morning (05:00 - 20:00)\n",
    "mean_price_day = asin_seller_df[asin_seller_df['hourTime'].apply(lambda x: 5 <= x < 20)]['price'].mean()\n",
    "print(f\"Mean price during the day (05:00 - 20:00): {mean_price_day}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ada2b59",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter DataFrame for the specified ASIN and sellerId\n",
    "asin_seller_df = df[(df['asin'] == \"B00605N1G4\") & (df['sellerId'] == \"ABGAQ3TO9PA1P\")]\n",
    "\n",
    "# Sort the DataFrame by 'time' to ensure the data is in chronological order\n",
    "asin_seller_df = asin_seller_df.sort_values('time')\n",
    "\n",
    "# Initialize a counter for consecutive occurrences and a maximum counter\n",
    "consec_counter = 0\n",
    "max_consec = 0\n",
    "consec_hours = []\n",
    "max_consec_hours = []\n",
    "\n",
    "# Loop through the DataFrame\n",
    "for idx, row in asin_seller_df.iterrows():\n",
    "    # If the price is 60.85, increment the counter\n",
    "    if row['price'] == 60.85:\n",
    "        consec_counter += 1\n",
    "        consec_hours.append(row['hourTime'])\n",
    "        # If this is a new maximum, update the maximum counter and hours\n",
    "        if consec_counter > max_consec:\n",
    "            max_consec = consec_counter\n",
    "            max_consec_hours = consec_hours.copy()  # make sure to copy the list, not just reference it\n",
    "    # If the price is not 60.85, reset the counter and hours list\n",
    "    else:\n",
    "        consec_counter = 0\n",
    "        consec_hours = []\n",
    "\n",
    "print(f\"The maximum number of consecutive times the price was set to 60.85 is: {max_consec}\")\n",
    "print(f\"This occurred at the following hours: {max_consec_hours}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22de7e02",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Filter DataFrame for the specified ASIN and sellerId\n",
    "asin_seller_df = df[(df['asin'] == \"B00605N1G4\") & (df['sellerId'] == \"ABGAQ3TO9PA1P\")]\n",
    "\n",
    "# Convert 'time' to datetime object\n",
    "asin_seller_df['time'] = pd.to_datetime(asin_seller_df['time'])\n",
    "\n",
    "# Create a 'hour' column based on the 'time' column\n",
    "asin_seller_df['hour'] = asin_seller_df['time'].dt.hour\n",
    "\n",
    "# Group by 'hour' and 'price', then drop duplicates and sort by 'hour'\n",
    "price_hour_combinations = asin_seller_df[['hour', 'price']].drop_duplicates().sort_values('price')\n",
    "\n",
    "# Count occurrence of each combination\n",
    "price_hour_counts = asin_seller_df.groupby(['hour', 'price']).size().reset_index(name='counts')\n",
    "\n",
    "print(price_hour_combinations)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5173f910",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter DataFrame for the specified ASIN\n",
    "asin_df = df[df['asin'] == \"B00605N1G4\"]\n",
    "\n",
    "# Group by 'sellerId' and calculate the minimum and maximum of 'price'\n",
    "grouped_df = asin_df.groupby('sellerId')['price'].agg(['min', 'max']).reset_index()\n",
    "\n",
    "print(grouped_df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2a05aa2",
   "metadata": {},
   "source": [
    "## Einstellbar wie viele Seller pro plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "629f498b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "# Extract unique ASINs\n",
    "unique_asins = df['asin'].unique()\n",
    "\n",
    "# Sellers to exclude\n",
    "exclude_sellers = [\"\"]\n",
    "\n",
    "# Loop over unique ASINs\n",
    "for asin in unique_asins:\n",
    "    # Filter DataFrame for the selected ASIN and select necessary columns\n",
    "    # Exclude the sellers listed in 'exclude_sellers'\n",
    "    asin_df = df[(df['asin'] == asin) & (~df['sellerId'].isin(exclude_sellers))][['time', 'price', 'sellerId', 'is_algorithmic']].copy()\n",
    "\n",
    "    # Convert 'time' to datetime object\n",
    "    asin_df['time'] = pd.to_datetime(asin_df['time'])\n",
    "\n",
    "    # Group by 'time', 'sellerId', and 'is_algorithmic', calculate mean of 'price'\n",
    "    grouped_df = asin_df.groupby(['time', 'sellerId', 'is_algorithmic']).mean().reset_index()\n",
    "\n",
    "    # Add algorithmic info to sellerId\n",
    "    grouped_df['sellerId'] = grouped_df.apply(lambda row: f\"{row['sellerId']} (Algorithmic)\" if row['is_algorithmic'] else f\"{row['sellerId']}\", axis=1)\n",
    "\n",
    "    # Pivot the DataFrame\n",
    "    pivot_df = grouped_df.pivot(index='time', columns='sellerId', values='price')\n",
    "\n",
    "    # Check if only two sellers are present\n",
    "    if len(pivot_df.columns) == 4:\n",
    "        # Print seller ids\n",
    "        print(\"Seller IDs for ASIN \", asin, \": \", pivot_df.columns.tolist())\n",
    "\n",
    "        # Plot the data\n",
    "        fig, ax = plt.subplots(figsize=(15, 7))\n",
    "        pivot_df.plot(kind='line', ax=ax)\n",
    "        plt.xlabel('Time')\n",
    "        plt.ylabel('Price')\n",
    "        plt.title(f'Price History Across Sellers for Asin: {asin}')\n",
    "        plt.tight_layout()\n",
    "\n",
    "        # Move the legend outside the plot on the right\n",
    "        ax.legend(loc='center left', bbox_to_anchor=(1, 0.5))\n",
    "\n",
    "        # Save the plot to a PNG file, including the legend\n",
    "        plt.savefig(f'{asin}_plot.png', bbox_inches='tight')\n",
    "\n",
    "        plt.show()\n",
    "\n",
    "        print(\"This is the ASIN\", asin)\n",
    "\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d391dee3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a023fc90",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter DataFrame for the specified ASIN\n",
    "asin_df = df[df['asin'] == \"B0062VH4NM\"]\n",
    "\n",
    "# Group by 'sellerId' and calculate the minimum and maximum of 'price'\n",
    "grouped_df = asin_df.groupby('sellerId')['price'].agg(['min', 'max']).reset_index()\n",
    "\n",
    "print(grouped_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a84ab935",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Filter DataFrame for the specified ASIN\n",
    "asin_df = df[df['asin'] == \"B077T3QZ1H\"]\n",
    "\n",
    "# Group by 'sellerId' and calculate the minimum and maximum of 'price'\n",
    "grouped_df = asin_df.groupby('sellerId')['price'].agg(['min', 'max']).reset_index()\n",
    "\n",
    "print(grouped_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e692a0da",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
