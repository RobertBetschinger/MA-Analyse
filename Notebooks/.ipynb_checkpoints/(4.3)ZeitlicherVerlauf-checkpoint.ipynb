{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4a65ed78",
   "metadata": {},
   "source": [
    "## Load and preprocess data, then calculate the number of unique algorithmic and non-algorithmic sellers.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "04d87ad0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Es gibt insgesamt 1924 verschiedene Verkäufer\n",
      "Es gibt insgesamt 1540 Non-Algo Verkäufer\n",
      "Es gibt insgesamt 384 Algo Verkäufer\n",
      "Sie Summieren sich richtig auf True\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "df = pd.read_csv('../Grunddatein/Zwischendatein/cleaned_data.csv')\n",
    "##Transform Time Coulumn to Time Format\n",
    "df[\"time\"] = pd.to_datetime(df[\"time\"], format=\"%Y-%m-%d %H:%M:%S\")\n",
    "\n",
    "##Transform CrawlTime Column to Fortmat\n",
    "df['crawlTime'] = pd.to_datetime(df['crawlTime'])\n",
    "\n",
    "## Exclude all Rows where condition isnt New and which where a reactive Crawl\n",
    "df = df[df['trigByReactive'] != True]\n",
    "df = df[df['condition'].isin(['Neu', 'New'])]\n",
    "\n",
    "##Get the Number of Distinct Values\n",
    "distinct_values_verkäufer = df['sellerName'].unique()\n",
    "print(f\"Es gibt insgesamt {len(distinct_values_verkäufer)} verschiedene Verkäufer\")\n",
    "\n",
    "##Read in the Sellers who are algorithmic\n",
    "df_algorithmic_seller_names = pd.read_csv('../Grunddatein/Zwischendatein/PA-Adopters.csv')\n",
    "df_algorithmic_seller_names = df_algorithmic_seller_names.rename(columns={'AlgorithmicSellerNames': 'sellerName'})  # rename column\n",
    "\n",
    "\n",
    "# Create a new column to indicate if the seller is algorithmic or not\n",
    "df['is_algorithmic'] = df['sellerName'].isin(df_algorithmic_seller_names['sellerName'])\n",
    "\n",
    "# Calculate the number of algorithmic and non-algorithmic sellers\n",
    "num_algo_sellers = df[df['is_algorithmic']]['sellerName'].nunique()\n",
    "num_non_algo_sellers = df[~df['is_algorithmic']]['sellerName'].nunique()\n",
    "\n",
    "print(f\"Es gibt insgesamt {num_non_algo_sellers} Non-Algo Verkäufer\")\n",
    "print(f\"Es gibt insgesamt {num_algo_sellers} Algo Verkäufer\")\n",
    "print(f\"Sie Summieren sich richtig auf\",num_algo_sellers + num_non_algo_sellers == len(distinct_values_verkäufer))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cb3bd89",
   "metadata": {},
   "source": [
    "## Determine the number of unique ASINs associated with Amazon and non-Amazon sellers, and verify if their sum matches the total unique ASINs in the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4d82a6c3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "An so vielen Asins ist Amazon als Verkäufer eingetragen:646\n",
      "An so vielen Asins ist Amazon nicht als Verkäufer eingetragen:325\n",
      "So Viele unterschiedliche Asins gibt es maximal 971\n",
      "Sie Summieren sich richtig auf True\n"
     ]
    }
   ],
   "source": [
    "amazon_asin_values = df.loc[df['sellerName'].isin(['amazon', 'Amazon Warehouse ', 'Amazon US', 'Amazon UK']), 'asin'].unique()\n",
    "print(f\"An so vielen Asins ist Amazon als Verkäufer eingetragen:{len(amazon_asin_values)}\")\n",
    "\n",
    "# Assuming the DataFrame is named 'df'\n",
    "all_asin_values = df['asin'].unique()\n",
    "\n",
    "# Subtract the values that exist in the 'amazon_asin_values' list\n",
    "non_amazon_asin_values = set(all_asin_values) - set(amazon_asin_values)\n",
    "print(f\"An so vielen Asins ist Amazon nicht als Verkäufer eingetragen:{len(non_amazon_asin_values)}\")\n",
    "print(f\"So Viele unterschiedliche Asins gibt es maximal {len(all_asin_values)}\")\n",
    "\n",
    "# Create a DataFrame with only Amazon-sold products\n",
    "amazon_df = df[df['asin'].isin(amazon_asin_values)]\n",
    "# Create a DataFrame with only non-Amazon-sold products\n",
    "non_amazon_df = df[df['asin'].isin(non_amazon_asin_values)]\n",
    "# Calculate the number of unique ASINs in each data frame\n",
    "amazon_unique_asins = len(amazon_df['asin'].unique())\n",
    "non_amazon_unique_asins = len(non_amazon_df['asin'].unique())\n",
    "\n",
    "print(f\"Sie Summieren sich richtig auf\", amazon_unique_asins + non_amazon_unique_asins == len(all_asin_values))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10ccbdad",
   "metadata": {},
   "source": [
    "## Create a New Dataframe. The dataframe contains asins where at least 2 Algo Sellers exist. Print out the length of the Dataframe, or the Number of asins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6c80a94a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of ASINs with at least 3 Algo Sellers: 396\n",
      "ASINs with at least 3 algorithmic sellers saved to 'asins_with_three_algo_sellers.csv'\n"
     ]
    }
   ],
   "source": [
    "# Group the original dataframe by 'asin'\n",
    "grouped_df_for_asins = df.groupby('asin')\n",
    "\n",
    "# Define a function to filter groups with at least 3 distinct algorithmic sellers\n",
    "def filter_at_least_three_algo_sellers(group):\n",
    "    distinct_sellers = group['sellerName'].unique()\n",
    "    algo_seller_count = np.sum(np.isin(distinct_sellers, df_algorithmic_seller_names['sellerName']))\n",
    "    return algo_seller_count >= 3\n",
    "\n",
    "# Apply the function to the grouped data and save the results in a new DataFrame\n",
    "three_algo_sellers_df = grouped_df_for_asins.filter(filter_at_least_three_algo_sellers)\n",
    "\n",
    "# Get the unique ASINs in the new DataFrame\n",
    "unique_asins_with_three_algo_sellers = three_algo_sellers_df['asin'].unique()\n",
    "\n",
    "# Print the length of the DataFrame or the number of ASINs\n",
    "print(f\"Number of ASINs with at least 3 Algo Sellers: {len(unique_asins_with_three_algo_sellers)}\")\n",
    "\n",
    "# Print each ASIN and its associated algorithmic sellers\n",
    "#for asin in unique_asins_with_three_algo_sellers:\n",
    " #   asin_df = three_algo_sellers_df[three_algo_sellers_df['asin'] == asin]\n",
    "  #  algo_sellers = asin_df[asin_df['sellerName'].isin(df_algorithmic_seller_names['sellerName'])]['sellerName'].unique()\n",
    "    #print(f\"-------------\")\n",
    "    #print(f\"ASIN: {asin}, Algorithmic Sellers: {', '.join(algo_sellers)}\")\n",
    "\n",
    "# Save the unique ASINs with at least 3 algorithmic sellers to a new DataFrame\n",
    "asins_three_algo_sellers_df = pd.DataFrame(unique_asins_with_three_algo_sellers, columns=['asin'])\n",
    "\n",
    "# Save the DataFrame to a CSV file\n",
    "asins_three_algo_sellers_df.to_csv('asins_with_three_algo_sellers.csv', index=False)\n",
    "\n",
    "print(\"ASINs with at least 3 algorithmic sellers saved to 'asins_with_three_algo_sellers.csv'\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f158a1af",
   "metadata": {},
   "source": [
    "# Create a New Dataframe. The Dataframe contains asins where one algo and one none algo Seller exists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d3e603b3",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df_non_algorithmic_seller_names' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[9], line 13\u001b[0m\n\u001b[0;32m     10\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m algorithmic_present \u001b[38;5;129;01mand\u001b[39;00m non_algorithmic_present\n\u001b[0;32m     12\u001b[0m \u001b[38;5;66;03m# Step 3: Apply the function to the grouped data and save the results in a new DataFrame\u001b[39;00m\n\u001b[1;32m---> 13\u001b[0m mixed_sellers_df_amazon_products \u001b[38;5;241m=\u001b[39m \u001b[43mamazon_df\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfilter\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilter_mixed_sellers\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\groupby\\generic.py:1382\u001b[0m, in \u001b[0;36mDataFrameGroupBy.filter\u001b[1;34m(self, func, dropna, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1379\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m name, group \u001b[38;5;129;01min\u001b[39;00m gen:\n\u001b[0;32m   1380\u001b[0m     \u001b[38;5;28mobject\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__setattr__\u001b[39m(group, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mname\u001b[39m\u001b[38;5;124m\"\u001b[39m, name)\n\u001b[1;32m-> 1382\u001b[0m     res \u001b[38;5;241m=\u001b[39m func(group, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1384\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1385\u001b[0m         res \u001b[38;5;241m=\u001b[39m res\u001b[38;5;241m.\u001b[39msqueeze()\n",
      "Cell \u001b[1;32mIn[9], line 9\u001b[0m, in \u001b[0;36mfilter_mixed_sellers\u001b[1;34m(group)\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfilter_mixed_sellers\u001b[39m(group):\n\u001b[0;32m      8\u001b[0m     algorithmic_present \u001b[38;5;241m=\u001b[39m group[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msellerName\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39misin(df_algorithmic_seller_names[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msellerName\u001b[39m\u001b[38;5;124m'\u001b[39m])\u001b[38;5;241m.\u001b[39many()\n\u001b[1;32m----> 9\u001b[0m     non_algorithmic_present \u001b[38;5;241m=\u001b[39m group[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msellerName\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39misin(\u001b[43mdf_non_algorithmic_seller_names\u001b[49m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msellerName\u001b[39m\u001b[38;5;124m'\u001b[39m])\u001b[38;5;241m.\u001b[39many()\n\u001b[0;32m     10\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m algorithmic_present \u001b[38;5;129;01mand\u001b[39;00m non_algorithmic_present\n",
      "\u001b[1;31mNameError\u001b[0m: name 'df_non_algorithmic_seller_names' is not defined"
     ]
    }
   ],
   "source": [
    "## Zeitlicher Verlauf bei Non-Amazon Produkten\n",
    "\n",
    "# Step 1: Group non_amazon_df by 'asin' and 'time'\n",
    "amazon_df = amazon_df.groupby(['asin'])\n",
    "\n",
    "# Step 2: Define a function to filter groups with at least one algorithmic and one non-algorithmic seller\n",
    "def filter_mixed_sellers(group):\n",
    "    algorithmic_present = group['sellerName'].isin(df_algorithmic_seller_names['sellerName']).any()\n",
    "    non_algorithmic_present = group['sellerName'].isin(df_non_algorithmic_seller_names['sellerName']).any()\n",
    "    return algorithmic_present and non_algorithmic_present\n",
    "\n",
    "# Step 3: Apply the function to the grouped data and save the results in a new DataFrame\n",
    "mixed_sellers_df_amazon_products = amazon_df.filter(filter_mixed_sellers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57b85917",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define a function to extract hour from datetime column\n",
    "def get_hour(datetime_val):\n",
    "    return datetime_val.hour\n",
    "\n",
    "# apply the get_hour function to the 'time' column using apply method\n",
    "mixed_sellers_df_amazon_products['hourTime'] = mixed_sellers_df_amazon_products['time'].apply(get_hour)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94f536bd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "276cbe81",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.dates as mdates\n",
    "import pandas as pd\n",
    "import random\n",
    "\n",
    "# Step 1: Filter the ASINs with a range of 4-5 sellers\n",
    "asin_seller_counts = mixed_sellers_df_amazon_products.groupby('asin')['sellerName'].nunique()\n",
    "filtered_asins = asin_seller_counts[(asin_seller_counts >= 3) & (asin_seller_counts <= 5)].index\n",
    "\n",
    "# Step 2: Select a random ASIN from the filtered ASINs\n",
    "random_asin = random.choice(filtered_asins)\n",
    "\n",
    "# Step 3: Filter the DataFrame for the selected ASIN\n",
    "asin_specific_df = mixed_sellers_df_amazon_products[mixed_sellers_df_amazon_products['asin'] == random_asin].copy()\n",
    "\n",
    "# assuming your original dataframe is called 'asin_specific_df'\n",
    "selected_cols = ['time','crawlTime','asin','price', 'sellerName', 'hourTime']\n",
    "asin_specific_df = asin_specific_df[selected_cols]\n",
    "# swap hourTime values that are equal to 0 with 24\n",
    "asin_specific_df.loc[asin_specific_df['hourTime'] == 0, 'hourTime'] = 24\n",
    "\n",
    "# sort the dataframe by hourTime in descending order\n",
    "asin_specific_df_sorted = asin_specific_df.sort_values(by=['hourTime'], ascending=True)\n",
    "\n",
    "# display the sorted dataframe as an HTML table\n",
    "#HTML(asin_specific_df_sorted.to_html(index=False))\n",
    "asin = asin_specific_df['asin'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20ec0c21",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# assuming your dataframe is called 'asin_specific_df'\n",
    "selected_cols = ['price', 'sellerName', 'time','crawlTime']\n",
    "asin_specific_df = asin_specific_df[selected_cols]\n",
    "\n",
    "# ensure 'time' column is in datetime64[ns] format\n",
    "asin_specific_df['time'] = pd.to_datetime(asin_specific_df['time'])\n",
    "\n",
    "# group the data by time and sellerName and calculate the average price\n",
    "grouped_df = asin_specific_df.groupby(['time', 'sellerName']).mean().reset_index()\n",
    "\n",
    "# add seller type to sellerName\n",
    "grouped_df['sellerName'] = grouped_df['sellerName'].apply(\n",
    "    lambda x: f\"{x} (Algorithmic)\" if x in df_algorithmic_seller_names['sellerName'].values else f\"{x}\"\n",
    ")\n",
    "\n",
    "# pivot the table to get a separate column for each seller\n",
    "pivot_df = grouped_df.pivot(index='time', columns='sellerName', values='price')\n",
    "\n",
    "# plot the price history for each seller\n",
    "pivot_df.plot(kind='line')\n",
    "\n",
    "# set the x-axis label\n",
    "plt.xlabel('Time')\n",
    "\n",
    "# set the y-axis label\n",
    "plt.ylabel('Price')\n",
    "\n",
    "# set the plot title\n",
    "plt.title(f'Price History Across Sellers for Asin: {asin}')\n",
    "\n",
    "# move legend to the right\n",
    "plt.legend(loc='center left', bbox_to_anchor=(1.0, 0.5))\n",
    "\n",
    "# show the plot\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60a4987e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
